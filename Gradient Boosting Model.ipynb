{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predition of stars for Training dataset based on our models (text mining model and random forest model):\n",
    "#### 1. Perform 5_fold cross_validation to get predition for every entry of our training dataset \n",
    "#### 2. Repeat the previous step for 20 times and take mean as our predition \n",
    "\n",
    "### Combine those two prediction and use a Gradient Boosting mode to predict the stars of each business\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import imp\n",
    "import sklearn as sk\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import json\n",
    "import csv\n",
    "import unicodecsv\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import lda\n",
    "import csv\n",
    "#imp.reload(sys)\n",
    "#sys.stdout = codecs.getwriter('utf-8')(sys.stdout)\n",
    "#sys.stderr = codecs.getwriter('utf-8')(sys.stderr)\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import nltk\n",
    "import re\n",
    "import math\n",
    "from nltk.probability import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('',\n",
       " 'funny',\n",
       " 'user_id',\n",
       " 'review_id',\n",
       " 'text',\n",
       " 'business_id',\n",
       " 'stars',\n",
       " 'date',\n",
       " 'useful',\n",
       " 'type',\n",
       " 'cool')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list = []\n",
    "with open('/Users/Ellie/Documents/BERKELEY/STAT154/Proj/data_updata/yelp_academic_dataset_review_train.csv', encoding = 'utf8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for line in reader:\n",
    "        review_list.append(tuple(line))\n",
    "        \n",
    "review_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_review = pd.read_csv('/Users/Ellie/Documents/BERKELEY/STAT154/Proj/data_updata/outputchin.csv', index_col=0)\n",
    "text = pd.read_csv(\"~/Documents/BERKELEY/STAT154/Proj/out5.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_id = [element[5] for element in review_list]\n",
    "all_business_id = np.unique(business_id)\n",
    "stars = [int(element[6]) for element in review_list]\n",
    "real_value = pd.DataFrame({'business_id': business_id, 'stars': stars})\n",
    "real_value = real_value.groupby('business_id')['stars'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform cross validation\n",
    "cv_id = []\n",
    "for i in range(0, 5):\n",
    "    cv_id.extend([i] * 502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict stars for training dataset based on text mining model\n",
    "sample = [[] for i in range(len(review_list))]\n",
    "for j in range(0, 20): \n",
    "    random.shuffle(cv_id)\n",
    "    for i in range(0,5):\n",
    "        train_id = [all_business_id[j] for j in range(0, len(all_business_id)) if cv_id[j] != i]\n",
    "        test_id = [all_business_id[j] for j in range(0, len(all_business_id)) if cv_id[j] == i]\n",
    "        #         train_id = [all_business_id[i - 1] for i in train_business]\n",
    "        #         test_id = [all_business_id[i - 1] for i in test_buisness]\n",
    "        train_index = [i for i in range(0, len(review_list)) if review_list[i][5] in train_id]\n",
    "        test_index = [i for i in range(0, len(review_list)) if review_list[i][5] in test_id]\n",
    "\n",
    "        train_list = [review_list[j][4] for j in train_index]\n",
    "        train_response = [review_list[j][6] for j in train_index]\n",
    "        #     train_list_id = [element[5] for element in train_set]\n",
    "        test_list = [review_list[j][4] for j in test_index]\n",
    "        test_response = [review_list[j][6] for j in test_index]\n",
    "        #     test_list_id = [review_list[j][5] for j in test_index]\n",
    "\n",
    "        text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2', alpha = 3.4322448979591842e-05, n_iter=5, random_state=42))])\n",
    "        text_clf = text_clf.fit(train_list, train_response)\n",
    "        pred = text_clf.predict(test_list)\n",
    "        pred = pred.astype(int).tolist()\n",
    "        for i in test_index:\n",
    "            sample[i].append(pred.pop(0))\n",
    "#     result = pd.DataFrame({'business_id': test_list_id, 'stars': pred})\n",
    "#     result_agg = result.groupby(by = ['business_id'])['stars'].mean()\n",
    "#     result_agg = result_agg.reset_index()\n",
    "    \n",
    "#     result_act = pd.DataFrame({'business_id': test_list_id, 'stars': list(map(int, test_response))})\n",
    "#     result_act = result_act.groupby(by = ['business_id'])['stars'].mean()\n",
    "#     result_act = result_act.reset_index()    \n",
    "#     combine = pd.merge(result_agg, result_act, on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list_id = [element[5] for element in review_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_mean = [float(np.mean(i)) for i in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## text is a dataframe of predicted stars \n",
    "text = pd.DataFrame({'business_id': train_list_id, 'stars': sample_mean})\n",
    "text = text.groupby(by = ['business_id'])['stars'].mean()\n",
    "text = text.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2510"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116260"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross validation\n",
    "cv_id = []\n",
    "for i in range(0, 5):\n",
    "    cv_id.extend([i] * 495)\n",
    "cv_id.extend([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict stars for training dataset based on random forest model\n",
    "business = [[] for i in range(len(review_list))]\n",
    "for j in range(0, 20):\n",
    "    random.shuffle(cv_id)\n",
    "    for i in range(0, 5):\n",
    "        train_index = [index for index in range(0, len(business_review)) if cv_id[index] != i]\n",
    "        test_index = [index for index in range(0, len(business_review)) if cv_id[index] == i]\n",
    "        train_business = business_review.iloc[train_index]\n",
    "        test_business = business_review.iloc[test_index]\n",
    "        train = train_business.drop('stars', axis=1)\n",
    "        train = train.drop('business_id', axis=1)\n",
    "        test = test_business.drop('stars', axis=1)\n",
    "        test = test.drop('business_id', axis=1)\n",
    "        train_y = train_business['stars']\n",
    "        clr = RandomForestRegressor(n_jobs = 5, n_estimators = 1000)\n",
    "        clr.fit(train,train_y)\n",
    "        predictions = clr.predict(test)\n",
    "        predictions = predictions.astype(float).tolist()\n",
    "        for t in test_index:\n",
    "            business[t].append(predictions.pop(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business1 = business[0:len(business_review)]\n",
    "sample_business = [float(np.mean(i)) for i in business1]\n",
    "bus = pd.DataFrame({'business_id': business_review.business_id, 'stars': sample_business})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_value = real_value.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = pd.merge(text, bus, on = 'business_id')\n",
    "final = pd.merge(final, real_value, on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_train = final[[1,2]].as_matrix()\n",
    "final_response = final[[3]].as_matrix()\n",
    "final_response = [float(final_response[i]) for i in range(0, len(final_response))]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_testing = test_business[[1,2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Model\n",
    "boost_lm = GradientBoostingRegressor()\n",
    "boost_lm.fit(final_train, final_response)\n",
    "pred = boost_lm.predict(final_testing)\n",
    "result = pd.DataFrame({'business_id': test_business.business_id, 'stars': pred})\n",
    "result.to_csv(\"out5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
