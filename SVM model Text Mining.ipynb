{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file tunes the alpha parameter for our text mining svm model\n",
    "#### sample with replacement 1000 times with a five-folder cross validation in order to find the optimal tuning parameter, alpha \n",
    "#### optimal alpha equals to 3.10270270e-05\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import imp\n",
    "import sklearn as sk\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import json\n",
    "import csv\n",
    "import unicodecsv\n",
    "import codecs\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import lda\n",
    "import csv\n",
    "#imp.reload(sys)\n",
    "#sys.stdout = codecs.getwriter('utf-8')(sys.stdout)\n",
    "#sys.stderr = codecs.getwriter('utf-8')(sys.stderr)\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import nltk\n",
    "import re\n",
    "import math\n",
    "from nltk.probability import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('',\n",
       " 'funny',\n",
       " 'user_id',\n",
       " 'review_id',\n",
       " 'text',\n",
       " 'business_id',\n",
       " 'stars',\n",
       " 'date',\n",
       " 'useful',\n",
       " 'type',\n",
       " 'cool')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test on \"final_pos_neg_sentences.csv\" \n",
    "review_list = []\n",
    "with open('/Users/Ellie/Documents/BERKELEY/STAT154/Proj/data_updata/yelp_academic_dataset_review_train.csv', encoding = 'utf8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for line in reader:\n",
    "        review_list.append(tuple(line))\n",
    "        \n",
    "review_list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform cross validation\n",
    "cv_id = []\n",
    "for i in range(0, 5):\n",
    "    cv_id.extend([i] * 502)\n",
    "random.shuffle(cv_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "value = []\n",
    "p = []\n",
    "all_business_id = np.unique(business_id)\n",
    "for val in np.linspace(10 ** (-3), 10 ** (-7), 1000): \n",
    "    mse = []\n",
    "    for i in range(0,5):\n",
    "        train_business = [j for j in range(1, len(all_business_id)) if cv_id[j] != i]\n",
    "        test_buisness = [j for j in range(1, len(all_business_id)) if cv_id[j] == i]\n",
    "        train_id = [all_business_id[i - 1] for i in train_business]\n",
    "        test_id = [all_business_id[i - 1] for i in test_buisness]\n",
    "        train_index = [i for i in range(1, len(review_list)-1) if review_list[i][5] in train_id]\n",
    "        test_index = [i for i in range(1, len(review_list) -1) if review_list[i][5] in test_id]\n",
    "\n",
    "        train_list = [review_list[j][4] for j in train_index]\n",
    "        train_response = [review_list[j][6] for j in train_index]\n",
    "        #     train_list_id = [element[5] for element in train_set]\n",
    "        test_list = [review_list[j][4] for j in test_index]\n",
    "        test_response = [review_list[j][6] for j in test_index]\n",
    "        test_list_id = [review_list[j][5] for j in test_index]\n",
    "        \n",
    "        ## SVM model \n",
    "        text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2', alpha = val, n_iter=5, random_state=42))])\n",
    "        text_clf = text_clf.fit(train_list, train_response)\n",
    "        pred = text_clf.predict(test_list)\n",
    "        pred = pred.astype(int)\n",
    "        result = pd.DataFrame({'business_id': test_list_id, 'stars': pred})\n",
    "        result_agg = result.groupby(by = ['business_id'])['stars'].mean()\n",
    "        result_agg = result_agg.reset_index()\n",
    "\n",
    "        result_act = pd.DataFrame({'business_id': test_list_id, 'stars': list(map(int, test_response))})\n",
    "        result_act = result_act.groupby(by = ['business_id'])['stars'].mean()\n",
    "        result_act = result_act.reset_index()    \n",
    "        combine = pd.merge(result_agg, result_act, on = 'business_id')\n",
    "        mse.append(np.mean((combine['stars_x'] - combine['stars_y'])**2))\n",
    "    value.append(np.mean(mse))\n",
    "    p.append(val)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(p, mse)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(\"CV MSE v.s. Alpha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The whole data set\n",
    "train_set = [element[4] for element in review_list]\n",
    "train_response = [element[6] for element in review_list]\n",
    "train_list_id = [element[5] for element in review_list]\n",
    "test_set = [element[4] for element in test_list]\n",
    "test_list_id = [element[5] for element in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2', alpha = 3.10270270e-05, n_iter=5, random_state=42))])\n",
    "text_clf = text_clf.fit(train_set, train_response)\n",
    "pred = text_clf.predict(test_set)\n",
    "pred = pred.astype(int)\n",
    "result = pd.DataFrame({'business_id': test_list_id, 'stars': pred})\n",
    "result_agg = result.groupby(by = ['business_id'])['stars'].mean()\n",
    "result_agg = result_agg.reset_index()\n",
    "result_agg.to_csv(\"outtext.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
